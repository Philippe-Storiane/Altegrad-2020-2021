\documentclass[a4paper]{article}
\usepackage{graphicx}
\usepackage{float}

\input{style/head.tex}

%-------------------------------
%	TITLE VARIABLES (identify your work!)
%-------------------------------
%-------------------------------
%	TITLE VARIABLES (identify your work!)
%-------------------------------

\newcommand{\yourname}{Philippe BAZET} % replace YOURNAME with your name
\newcommand{\youremail}{pbazet@yahoo.com} % replace YOUREMAIL with your email
\newcommand{\assignmentnumber}{2} % replace X with the lab session number

\begin{document}

%-------------------------------
%	TITLE SECTION (do not modify unless you really need to)
%-------------------------------
\input{style/header.tex}

%-------------------------------
%	ASSIGNMENT CONTENT (add your responses)
%-------------------------------

\section{Question 1}
As mention in \cite{luong2016}, greedy decoding stragegy is "heavily" suboptimal, two alternative strategies are proposed
\begin{itemize}
\item Beam Research. At each step, instead of one single hypothesis, a fixed set of $K$ possibles translations are tested in parallel. From each of these $K$ possible translations, news probability are built for next new word. From this newly built hypothesis set, only $K$ most probable sentences are selected
\item Ensemble Research. An ensemble of different statistical learners are run separatly and final solution in made on building new proability by aggregating through predefined operators proability  from different learners
\end{itemize}

\subsection{Sub optimality for greedy research}

In greedy research, a local optimal solution is chosen. The one that choose the most probable word given already generated sentence. Meanwhile, the objective function is global: not select the highest possible next word but the whole sentence that is most probable. The higuest most probable  sentence may include word that are not most probable given words preceding a given word.

Global Objective function for given sentence $X$ translated from sentence $Y$ using notation from \citep{luong2016}
\begin{equation}
Objective_{global}(X) = Max Log (P( X \vert Y)) = \sum_{t} Log( P( x_{t} \vert x_{<t},Y)  
\end{equation}


Greedy objective function
\begin{equation}
Objective_{local}(x_{t}) = Max ( Log( P( x_{t} \vert x_{<t},Y))
\end{equation}


\subsection{Beam Research}
$K$ most probablement sentences $K_{t}$ are tested in parallel at time $t$

When trying to add a new word, probability are estimated for building new sentences from the $K_{t}$ hypothesis test set adding a new word. For each sentence $k_{t} \in K_{t}$, prediction is computed for new word from vocabulary, for $x_{t+1}$ word
\begin{equation}
prediction = Log(P(x_{t+1}^{k} \vert x_{<=t}^{k},Y))
\end{equation}

Prediction are then aggregated (summed) to log probability from $K$ sentences in order to compute probability for hypothesis for new sentences adding new word at end of sentence from $K$ sentences
From this new hypothesis sentences test set, the $K$ most probable sentence are selected for builing new $K_{t+1}$ hypothesis test set 

\subsection{ Ensemble Research}

$M$ concurrent statistical learners are run in parallel. For a given sentence, each learner $m \in M$ will give its probability $p^{m} = P(x_{t}^{m} \vert x_{<t}^{m})$ for next word in sentence. These probabilities are then combined using specific operators to build a probability for next word in sentence using probabilities from $M$ statistical learners. \citep{luong2016} propose two operators
\begin{itemize}
\item Majority Voting (average of probability of different learners)
\item Consensus $(\prod_{m=1}^{M} p^{m})^{1 / M}$

\end{itemize}





\section{Question 2}
Sentences are over translated: same words appear several times in translation, translating far more words that expected. Using approach from \cite{zhaopeng2016}, neural model should model translation coverage for input words. For a given step $t$ in translation, the translation coverage $C_{t}$ should model the usage of each input word in the translation process up to step $t$. The translation coverage model sould be used in the attention model of input context vector defined in \cite{luong2015},  the attention weights should be updated in order to give less attention to input word that have already been used in translation and thus theirs attention weights need to be adjusted (lowered) in order to enable usage (give more attention) in translation of other input word that have less been used in translation. The same way, coverage model should be modeled using attention weights as input parameter. The importance (weight) of an input word in a translation coverage is directly correlated to cumulated attention weights of a given input word\\
In this translation coverage sensitive neural model, objective function should also be adapted in order to additionnaly measure how effecfive the coverage model is to measure the real coverage of input word.\\

\subsubsection{Coverage translation model}
More formally, coverage model could be modelized as a vector $C_{t} \in R^{N}$ where $N$ is the maximum size of input sentence. For a given word at position $i$ in the input sentence, $C_{t,i}$ estimate coverage of input word. Instead of hard coverage that explicitly count hom many words have been translated, soft coverage is a probability estimate of such quantity. $C_{t,i}$ is estimated using a "neural netword equation" giving to a activation function, input parameters as
\begin{itemize}
\item $C_{t-1,i}$ coverage estimate for word at posiiton $i$ at previous step $t-1$
\item $\widehat{h}_{i}$ hidden state of encoder for location $i$
\item $h_{t-1}$ hidden state of translation at step $t-1$
\item $\alpha_{t-1,i}$ attention weight for input word at location $i$ and step $t-1$
\end{itemize}

\subsubsection{Updated attention model}
In attention model defined in \citep{luong2015}, several equations are proposed to score hidden state of translation $h_{t}$ with hidden state of input word $\widehat{h}_{i}$
\begin{itemize}
\item simple dot product $h^{T}_{t}h_{i}$ 
\item generalize $h_{t}W_{\alpha}\widehat{h}_{i}$
\item concat $v_{\alpha}^{T}tanh(W_{\alpha}[h_{t-1};\widehat{h}_{i}])$
\end{itemize}

$concat$ formulation is used for \citep{zhaopeng2016} and extended with an additional linear projection of translation coverage model $C_{t-1,i}$
\begin{equation}
score(h_{t},\widehat{h}_{i}) = v_{\alpha}^{T}tanh(W_{\alpha}[h_{t-1};\widehat{h}_{i}] + \boldsymbol{V_{\alpha}C_{t-1,i}})
\end{equation}


\subsubsection{Updated objective function}
Standard language model objective is maximizing log probability of translation $y$ given an input sentence $x$ and model $\theta$,  $Log(P(y \vert x;\theta)$. This objective  is extended with an estimate of loss between \begin{itemize}
\item estimated translation coverage model $\sum^{J}_{j=1}\Phi_{j}$
\item effective translation coverage $\sum^{J}_{j=1}\sum^{I}_{i=1}\alpha_{i,j}$
\end{itemize}  

For the estimated translation coverage, for a given inout word at location $j$, we sample between 0 and a constant $N$ a $\Phi_{j}$ estimate based on a sigmoid function depending on a linear projection of an hidden state $\widehat{h}_{j}$ of input word at location $j$, $sigmoid(U_{\alpha}\widehat{h}_{j})$. $N$ is a constant number estimating the maximum potential number of word that can be translated from a given input word\\
Effective translation coverage is performed by summing for a given input word attention weights of all output words 



\section{Question 3}

Two examples are given. One sentence from the test set in lab assignment "I have a red car"
An other exemple "A green banana is delicious". The inversions between adjective and noun is very well captured for the adjective (where attention for translated adjective is above 0.8) and partially captured for the noun  (where attention for translated noun is around 0.5) 
\begin{figure}[p]
\includegraphics[keepaspectratio=true,scale=0.9]{figures/green banana.png}
\caption{Alligment for translations "a green banana is delicious"}
\end{figure}

\begin{figure}
\includegraphics[keepaspectratio=true,scale=0.9]{figures/red car.png}
\caption{Alligments for "I have a red car"}
\end{figure}

\section{Question 4}
Output from Lab assignment
\begin{itemize}
\item Traslation for "I did not mean to hurt you" $\Rightarrow$
"je n ai pas voulu intention de blesser blesser blesser blesser blesser blesser . blesser . blesser . . . . . . . . . . . . ."
\item  Translation for "She is so mean" $\Rightarrow$
"elle est tellement méchant méchant"
\end{itemize}


Several phenomenons appear
  


\begin{itemize}
\item Different meaning for same word "mean".
\item Different grammatical usages for same word "mean" as a verb in first sentence and adjective in seconde sentence.
\item Context sensitivity. Same word "mean" depending on context has very different translation and grammatical properties (meaning and syntax for sample sentences)
\end{itemize}


Thus language model should be able to model different knoweldge level of translated words. 
\begin{itemize}
\item low level pure syntax with phenomenon 2
\item higher semantic level meaning with phenomemon 1
\end{itemize}

Language model should also be able to combine these different levels of knowledge, each level having a different contribution depending of  the language processing task (trasnlation, part of speach tagging etc..).\\

Furthermoe, language model should be able to adapt representation (embedding) of word to context, allowing for same word different representaton depending on context. Not one single context can be associated for a given word. This is a major change from Skip-gram or Continuous Bag of Word model of \cite{mikolov2013} first solution to associate to word a rich feature eautomated embedding. Context should embrace the full neighboroud of a word, thus both context words on the left and on the right of a given word\\

Additionnally, for a given task we cannot expect to be able to model all these aspects especially if the availale data set is limited. Thus language model should enable to be re used as a tool box for downstream tasks. Like in \cite{elmo2018}, one approach is to deliver output from a given language model as additional features to be re used possibly by enabling some parameter tuning of offered features. Alternatively as in \cite{bert2018}, the language model can be directly used as the model for downstream task. The language model is pre trained on some denoising tasks (task that artifically damage pre trained coprpus and that are trained to rebuilt the artificially damaged corpus). This pretrained language model can then be plugged in the downstream task. The preset parameters for the pretrained language model being updated during training phase of  the targeted downstream task.



\bibliographystyle{plain}
\bibliography{references} % citation records are in the references.bib document

\end{document}
