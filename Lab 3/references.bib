@inproceedings{luong2016,
  title={Neural Machine Translation},
  author={Thang Luong, Kyunghyun Cho, and Christophe Manning},
  booktitle={Assocation for Computational Linguistics},
  pages={XX,XX},
  year={2016}
}

@inproceedings{Vaswani2017,
  title={Attention is all you need},
  author={Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin},
  booktitle={Advances in neural information processing systems},
  pages={5998,6008},
  year={2017}
}

@inproceedings{radford2018,
  title={. Improving language understanding by generative pre-training},
  author={Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever},
  booktitle={International conference on Learning Representation},
  pages={1188,1196},
  year={2018}
}

@inproceedings{bert2018,
  title={ Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova},
  booktitle={International conference on machine learning},
  pages={1188,1196},
  year={2018}
}


